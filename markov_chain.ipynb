{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "markov_chain.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maneeshdisodia/DearML/blob/master/markov_chain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f193vgOzhRDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ref :https://sookocheff.com/post/nlp/ngram-modeling-with-markov-chains/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNs01Ttw4EI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = \"I am Sam. Sam I am. I do not like green eggs and ham.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_VsKcoJ4Qe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = s.split(\" \")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBK7DWuOcCXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigrams = [(tokens[i],tokens[i+1]) for i in range(0,len(tokens)-1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bctRzflgcEo2",
        "colab_type": "code",
        "outputId": "6da5937d-3c14-4417-bf09-ca4424e3cb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "bigrams"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'am'),\n",
              " ('am', 'Sam.'),\n",
              " ('Sam.', 'Sam'),\n",
              " ('Sam', 'I'),\n",
              " ('I', 'am.'),\n",
              " ('am.', 'I'),\n",
              " ('I', 'do'),\n",
              " ('do', 'not'),\n",
              " ('not', 'like'),\n",
              " ('like', 'green'),\n",
              " ('green', 'eggs'),\n",
              " ('eggs', 'and'),\n",
              " ('and', 'ham.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj2Lag17cGnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv08Re5ocWRU",
        "colab_type": "code",
        "outputId": "c752e0fb-57e0-4959-adfd-08288df1c84a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "random.sample(['am', 'am.', 'do'], 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['am']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3VAKRTNcX_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MarkovChain:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.memory = {}\n",
        "\n",
        "    def _learn_key(self, key, value):\n",
        "        if key not in self.memory:\n",
        "            self.memory[key] = []\n",
        "\n",
        "        self.memory[key].append(value)\n",
        "\n",
        "    def learn(self, text):\n",
        "        tokens = text.split(\" \")\n",
        "        bigrams = [(tokens[i], tokens[i + 1]) for i in range(0, len(tokens) - 1)]\n",
        "        for bigram in bigrams:\n",
        "            self._learn_key(bigram[0], bigram[1])\n",
        "\n",
        "    def _next(self, current_state):\n",
        "        next_possible = self.memory.get(current_state)\n",
        "\n",
        "        if not next_possible:\n",
        "            next_possible = self.memory.keys()\n",
        "\n",
        "        return random.sample(next_possible, 1)[0]\n",
        "\n",
        "    def babble(self, amount, state=''):\n",
        "        if not amount:\n",
        "            return state\n",
        "\n",
        "        next_word = self._next(state)\n",
        "        return state + ' ' + self.babble(amount - 1, next_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMPbdFh-cz84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVgXzwZvdGsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = MarkovChain()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBfQ8Xt3dJBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.learn('I am Sam.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8v3TunSeXHF",
        "colab_type": "code",
        "outputId": "1acb0074-0fef-491d-db80-d6ced3d11270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m.memory"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I': ['am'], 'am': ['Sam.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nitO3v1JeZuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.learn('I am Kevin.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsRTgyGYfCZT",
        "colab_type": "code",
        "outputId": "91a75ef6-3fdd-46dc-de3f-93b1974e0115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m.memory"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I': ['am', 'am'], 'am': ['Sam.', 'Kevin.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjkcENj9fFMc",
        "colab_type": "code",
        "outputId": "816edf96-54a5-44d5-e3e2-75489000aa85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m.babble(5,'the')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the probability of bigrams and babble'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7bgS0srfjds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.learn('Putting it all together we have a simple Markov Chain that can learn bigrams and babble text given the probability of bigrams that it has learned. Markov Chain’s are a simple way to store and query n-gram probabilities. Full source code for this example follows.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKyKY4B-gIkr",
        "colab_type": "code",
        "outputId": "9e490487-f8df-4b0f-8ed2-cfcf10ecda49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "m.memory"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Chain': ['that'],\n",
              " 'Chain’s': ['are'],\n",
              " 'Full': ['source'],\n",
              " 'I': ['am', 'am'],\n",
              " 'Markov': ['Chain', 'Chain’s'],\n",
              " 'Putting': ['it'],\n",
              " 'a': ['simple', 'simple'],\n",
              " 'all': ['together'],\n",
              " 'am': ['Sam.', 'Kevin.'],\n",
              " 'and': ['babble', 'query'],\n",
              " 'are': ['a'],\n",
              " 'babble': ['text'],\n",
              " 'bigrams': ['and', 'that'],\n",
              " 'can': ['learn'],\n",
              " 'code': ['for'],\n",
              " 'example': ['follows.'],\n",
              " 'for': ['this'],\n",
              " 'given': ['the'],\n",
              " 'has': ['learned.'],\n",
              " 'have': ['a'],\n",
              " 'it': ['all', 'has'],\n",
              " 'learn': ['bigrams'],\n",
              " 'learned.': ['Markov'],\n",
              " 'n-gram': ['probabilities.'],\n",
              " 'of': ['bigrams'],\n",
              " 'probabilities.': ['Full'],\n",
              " 'probability': ['of'],\n",
              " 'query': ['n-gram'],\n",
              " 'simple': ['Markov', 'way'],\n",
              " 'source': ['code'],\n",
              " 'store': ['and'],\n",
              " 'text': ['given'],\n",
              " 'that': ['can', 'it'],\n",
              " 'the': ['probability'],\n",
              " 'this': ['example'],\n",
              " 'to': ['store'],\n",
              " 'together': ['we'],\n",
              " 'way': ['to'],\n",
              " 'we': ['have']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqv-hrcX6ZXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}